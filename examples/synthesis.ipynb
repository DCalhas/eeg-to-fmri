{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a75880c",
   "metadata": {},
   "source": [
    "# EEG recoding to fMRI volume\n",
    "\n",
    "In this post I will go over the procedure to project an EEG instance to an fMRI. This work is the core of my PhD thesis and all the findings that consequently followed. The motivation of synthesizing an fMRI volume from EEG rests on:\n",
    "- An EEG recording setup is cheaper than an MRI laboratory setup;\n",
    "- The fMRI recording session in itself costs hundreds of dollars, whereas an EEG recording does not;\n",
    "- The main hypothesis of this work is to develop an informed fMRI view that allows better diagnosis than the EEG view alone, consequently having the potential of being applied in health care systems and reducing costs.\n",
    "\n",
    "## What is the model?\n",
    "\n",
    "In the [EEG to fMRI paper](https://arxiv.org/abs/2203.03481), the methodology to do this projection is presented.\n",
    "\n",
    "This model processes two inputs:\n",
    "- EEG representation $\\vec{x} \\in \\mathbb{R}^{C \\times F \\times T}$;\n",
    "- fMRI volume representation $\\vec{y} \\in \\mathbb{R}^{M_1 \\times M_2 \\times M_3}$.\n",
    "\n",
    "## What is an EEG?\n",
    "\n",
    "The EEG has a drift in relation to the associated fMRI volume, since it takes into consideration $10\\times \\mbox{TR}$ seconds in total (for the [NODDI](https://osf.io/94c5t/) dataset this corresponds to $10\\times 2.160=21.6$ seconds). In addition, the EEG has $C$ channels and $F$ frequency coefficients.\n",
    "\n",
    "## What is an fMRI?\n",
    "\n",
    "On the other hand, we have a **single** fMRI volume associated with the respective EEG. This fMRI is described by three dimensions, corresponding to the 3-dimensional axis, where $M_1=64$, $M_2=64$ and $M_3=30$.\n",
    "\n",
    "## Let us dive our hands into the code! And the mathematics behind it!\n",
    "\n",
    "In terms of code this corresponds to loading the data. First we start by import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e708bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import os\n",
    "#define the environment variables\n",
    "os.environ['EEG_FMRI_DATASETS']=\"/home/ist_davidcalhas/eeg_to_fmri/datasets\"\n",
    "os.environ['EEG_FMRI']=\"/home/ist_davidcalhas/eeg_to_fmri\"\n",
    "\n",
    "import eeg_to_fmri\n",
    "from eeg_to_fmri.utils import tf_config\n",
    "\n",
    "dataset=\"01\"\n",
    "tf_config.set_seed(seed=2)\n",
    "tf_config.setup_tensorflow(device=\"GPU\", memory_limit=1500, run_eagerly=True)\n",
    "\n",
    "from eeg_to_fmri.models.synthesizers import EEG_to_fMRI\n",
    "from eeg_to_fmri.data import preprocess_data, eeg_utils, data_utils\n",
    "from eeg_to_fmri.learning import train, losses\n",
    "from eeg_to_fmri import metrics\n",
    "from eeg_to_fmri.utils import viz_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eef5bc",
   "metadata": {},
   "source": [
    "Then we specify the number of individuals and $T$ (which corresponds to ```interval_eeg```), and load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3123545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget web.ist.utl.pt/ist180980/eeg_to_fmri/datasets/01.zip --directory-prefix=$EEG_FMRI/datasets/\n",
    "!unzip $EEG_FMRI/datasets/01.zip -d $EEG_FMRI/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c1969",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_individuals=getattr(data_utils, \"n_individuals_\"+dataset)\n",
    "interval_eeg=10\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    train_data, test_data = preprocess_data.dataset(dataset, n_individuals=n_individuals, interval_eeg=interval_eeg, ind_volume_fit=False, standardize_fmri=True, iqr=False, verbose=True)\n",
    "    eeg_train, fmri_train =train_data\n",
    "    eeg_test, fmri_test = test_data\n",
    "print(eeg_train.shape, fmri_train.shape)\n",
    "print(eeg_test.shape, fmri_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89207d5",
   "metadata": {},
   "source": [
    "In total, we are using $2296$ instances for training the model and $574$ constitute the testing set. After this we can start building the model. We first unroll the hyperparameters for the neural network: learning rate, weight decay, etc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573fd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eeg_to_fmri.models.synthesizers import parameters\n",
    "learning_rate,weight_decay ,kernel_size ,stride_size ,batch_size,latent_dimension,n_channels,max_pool,batch_norm,skip_connections,dropout,n_stacks,outfilter,local=parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ec839a",
   "metadata": {},
   "source": [
    "Note that both the ```eeg_to_fmri.models.synthesizers.parameters``` and the neural architectures' specification were obtained after exhaustive automatic searches. For the first, the Bayesian optimization algorithm [\\[1\\]](#references) was used and for the second the automatic neural architecture generation algorithm [\\[2\\]](#references).\n",
    "\n",
    "With these parameters, we can finally build the model and setup the optimizer, loss, training set and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eebcc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eeg_to_fmri.models.synthesizers import na_specification_eeg\n",
    "from eeg_to_fmri.models.fmri_ae import na_specification_fmri\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    model = EEG_to_fMRI(latent_dimension, eeg_train.shape[1:], na_specification_eeg, n_channels,\n",
    "                        weight_decay=weight_decay, skip_connections=True, batch_norm=True, fourier_features=True,\n",
    "                        random_fourier=True, topographical_attention=True, conditional_attention_style=True,\n",
    "                        conditional_attention_style_prior=False, local=True, seed=None, \n",
    "                        fmri_args = (latent_dimension, fmri_train.shape[1:], kernel_size, stride_size, n_channels, \n",
    "                        max_pool, batch_norm, weight_decay, skip_connections,\n",
    "                        n_stacks, True, False, outfilter, dropout, None, False, na_specification_fmri))\n",
    "    model.build(eeg_train.shape, fmri_train.shape)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "    loss_fn = losses.mae_cosine\n",
    "    train_set = tf.data.Dataset.from_tensor_slices((eeg_train, fmri_train)).batch(batch_size)\n",
    "    test_set= tf.data.Dataset.from_tensor_slices((eeg_test, fmri_test)).batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92432714",
   "metadata": {},
   "source": [
    "Note that the loss used minimizes the objective of approximating the EEG with the fMRI, along with the latent representations of each other, meaning:\n",
    "\n",
    "$$\\mathcal{L}(\\vec{x}, \\vec{y}) = ||\\vec{y}-\\hat{y}||_1^1  + 1-\\frac{\\vec{z}_x \\cdot \\vec{z}_y}{||\\vec{z}_x||_2^2\\cdot ||\\vec{z}_y||_2^2}$$\n",
    "\n",
    "This loss approximates the output (predicted fMRI) with the ground truth (fMRI volume) using the L1 distance and approximates the latent representations with a pattern based (cosine) distance.\n",
    "\n",
    "Finally, comes the fun part! The model is trained with the objective of producing an fMRI volume similar to the one paired with the given EEG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d244f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.train(train_set, model, optimizer, loss_fn, epochs=10, u_architecture=True, val_set=None, verbose=True, verbose_batch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e40334",
   "metadata": {},
   "source": [
    "Now we have a trained model that given an EEG representation, gives us an fMRI volume. You can check the visualization by using the visualization utilities file available in this repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f30991",
   "metadata": {},
   "outputs": [],
   "source": [
    "for eeg, fmri in test_set.repeat(1):\n",
    "    viz_utils.plot_3D_representation_projected_slices(model(eeg, fmri)[0].numpy()[0], threshold=0.37).show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530aeff1",
   "metadata": {},
   "source": [
    "Note that we give as input, to the model, the EEG and the fMRI representation, however our goal is to produce an fMRI volume without an EEG reference. If we check the call function of the model, we see that it returns a list of tensors, where the first tensor is the predicted fMRI without influence of the original fMRI and only dependent on the EEG.\n",
    "\n",
    "## References\n",
    "\n",
    "\\[1\\]: [Snoek, J., Larochelle, H., & Adams, R. P. (2012). Practical bayesian optimization of machine learning algorithms. Advances in neural information processing systems, 25.](https://proceedings.neurips.cc/paper/2012/hash/05311655a15b75fab86956663e1819cd-Abstract.html)\n",
    "\n",
    "\\[2\\]: [Calhas, D., Manquinho, V. M., & Lynce, I. (2021, November). Automatic Generation of Neural Architecture Search Spaces. In Combining Learning and Reasoning: Programming Languages, Formalisms, and Representations.](https://openreview.net/forum?id=TCvkaP15O7e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
